{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pl_bolts.transforms.dataset_normalizations import cifar10_normalization, emnist_normalization\n",
    "from torch import nn\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torchvision.datasets import CIFAR10, MNIST\n",
    "from torchvision import transforms \n",
    "\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT = r'/home/andrew/Documents/Data/Serialized_Aggregates'\n",
    "DATA_DIR = r'/home/andrew/Documents/Data/Torch'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE = r'MNIST508008.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR = os.path.join(ROOT, FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(ROOT, FILE), 'rb') as f:\n",
    "    pkg = pickle.load(f)\n",
    "\n",
    "x, y, _ = pkg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_transform=transforms.Compose([transforms.ToTensor(),\n",
    "                            emnist_normalization('mnist')\n",
    "                            ])\n",
    "cifar_transform=transforms.Compose([transforms.ToTensor(),\n",
    "                            cifar10_normalization()\n",
    "                            ])\n",
    "\n",
    "\n",
    "NAMES = {\n",
    "    'CIFAR10' : (CIFAR10, cifar_transform),\n",
    "    'MNIST' : (MNIST, mnist_transform)\n",
    "}\n",
    "\n",
    "class ImageDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, train_dir, name, batch_size, num_workers, dataset_root=None) -> None:\n",
    "        super(ImageDataModule).__init__()\n",
    "\n",
    "        root = dataset_root if dataset_root else '/'\n",
    "\n",
    "        self.source = train_dir\n",
    "        self.sink = os.path.join(root, name)\n",
    "        self.name = name\n",
    "\n",
    "        self.batch = batch_size\n",
    "        self.workers = num_workers\n",
    "\n",
    "    def prepare_data(self):\n",
    "        pass \n",
    "\n",
    "    def setup(self, stage: Optional[str] = None): # Will make this cleaner later\n",
    "        if stage == \"fit\" or stage is None:\n",
    "            with open(self.source, 'rb') as f:\n",
    "                x, y, _ = pickle.load(f)\n",
    "                ds, transform = NAMES[self.name]\n",
    "            self.train, self.validate = TensorDataset(torch.Tensor(x), torch.Tensor(y)), ds(self.sink, train=False, download=True, transform=transform)\n",
    "\n",
    "        # Assign test dataset for use in dataloader(s)\n",
    "        if stage == \"test\" or stage is None:\n",
    "            ds, transform = NAMES[self.name]\n",
    "\n",
    "            self.test = ds(self.sink, train=False, download=True, transform=transform)\n",
    "            \n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train, batch_size=self.batch, num_workers=self.workers)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.validate, batch_size=self.batch, num_workers=self.workers)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.test, batch_size=self.batch, num_workers=self.workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = ImageDataModule(DIR, 'MNIST', 8, 2, DATA_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader.setup('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = loader.test_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x7f13a5166fe0>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pl_bolts.models.autoencoders.components import (\n",
    "    resnet18_decoder,\n",
    "    resnet18_encoder,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_conv(input_vol, stack, kernel_size, stride, padding):\n",
    "    vol = input_vol\n",
    "    for i in range(len(stack)):\n",
    "        vol = ((vol - kernel_size + 2 * padding) / stride) + 1\n",
    "    return int(vol * vol * stack[-1])\n",
    "\n",
    "class classifier_head(pl.LightningModule):\n",
    "    def __init__(self, conv_stack, linear_stack, input_height=32, in_channels=3, n_class=10, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        layers = []\n",
    "        in_dim = in_channels\n",
    "        \n",
    "        for size in conv_stack:\n",
    "            layers.append(\n",
    "                nn.Sequential(\n",
    "                        nn.Conv2d(in_dim, size, 3),\n",
    "                        nn.BatchNorm2d(size),\n",
    "                        nn.ReLU()\n",
    "                )\n",
    "            )\n",
    "            in_dim = size\n",
    "        layers.append(nn.Flatten())\n",
    "        in_dim = compute_conv(input_height, conv_stack, 3, 1, 0)\n",
    "        for size in linear_stack:\n",
    "            layers.append(\n",
    "                nn.Sequential(\n",
    "                        nn.Linear(in_dim, size),\n",
    "                        nn.ReLU()\n",
    "                )\n",
    "            )\n",
    "            in_dim = size\n",
    "        layers.append(\n",
    "            nn.Sequential(\n",
    "                    nn.Linear(linear_stack[-1], n_class),\n",
    "                    nn.Softmax()\n",
    "            )\n",
    "        )\n",
    "        self.classifier = nn.Sequential(*layers)\n",
    "    def forward(self, x):\n",
    "        return self.classifier(x)\n",
    "\n",
    "class VAEclassifier(pl.LightningModule):\n",
    "    def __init__(self, \n",
    "            head,\n",
    "            enc_out_dim=512, \n",
    "            latent_dim=10, \n",
    "            categorical_dim=10,\n",
    "            input_height=32, \n",
    "            in_channels=3,\n",
    "            temperature: float = 0.5,\n",
    "            min_temperature: float = 0.2,\n",
    "            anneal_rate: float = 3e-5,\n",
    "            anneal_interval: int = 100, # every 100 batches\n",
    "            alpha: float = 1.,\n",
    "            kl_coeff = 1.,\n",
    "            **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        \n",
    "        gen_param = lambda x : nn.Parameter(torch.Tensor([x]))\n",
    "\n",
    "        self.save_hyperparameters(ignore='head')\n",
    "\n",
    "        self.l_dim = latent_dim\n",
    "        self.c_dim = categorical_dim\n",
    "\n",
    "        self.t = gen_param(temperature)\n",
    "        self.min_t = gen_param(min_temperature)\n",
    "        self.rate = gen_param(anneal_rate)\n",
    "        self.interval = gen_param(anneal_interval)\n",
    "        self.alpha = gen_param(alpha)\n",
    "        self.kl_coeff = gen_param(kl_coeff)\n",
    "\n",
    "        # encoder, decoder\n",
    "        self.encoder = resnet18_encoder(False, False)\n",
    "        self.decoder = resnet18_decoder(\n",
    "                        latent_dim=latent_dim * categorical_dim,\n",
    "                        input_height=input_height,\n",
    "                        first_conv=False,\n",
    "                        maxpool1=False\n",
    "                        )\n",
    "        self.encoder.conv1 = nn.Conv2d(in_channels, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.head = head\n",
    "\n",
    "        # distribution parameters\n",
    "        self.fc_z = nn.Linear(enc_out_dim, latent_dim * categorical_dim)\n",
    "        \n",
    "        # for the gaussian likelihood\n",
    "        self.log_scale = nn.Parameter(torch.Tensor([0.0]))\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=1e-4)\n",
    "\n",
    "    def gaussian_likelihood(self, x_hat, logscale, x):\n",
    "        scale = torch.exp(logscale)\n",
    "        mean = x_hat\n",
    "        dist = torch.distributions.Normal(mean, scale)\n",
    "\n",
    "        # measure prob of seeing image under p(x|z)\n",
    "        log_pxz = dist.log_prob(x)\n",
    "        return log_pxz.sum(dim=(1, 2, 3))\n",
    "\n",
    "    def kl_divergence(self, q, eps=1e-20):\n",
    "        q_p = nn.functional.softmax(q, dim=-1)\n",
    "        e = q_p * torch.log(q_p + eps)\n",
    "        ce = q_p * np.log(1. / self.c_dim + eps)\n",
    "\n",
    "        kl = torch.mean(torch.sum(e - ce, dim =(1,2)), dim=0)\n",
    "        return kl\n",
    "    \n",
    "    def reparameterize(self, z, eps=1e-20):\n",
    "        u = torch.rand_like(z)\n",
    "        g = - torch.log(- torch.log(u + eps) + eps)\n",
    "\n",
    "        # Gumbel-Softmax Trick\n",
    "        s = nn.functional.softmax((z + g) / self.t, dim=-1)\n",
    "        s = s.view(-1, self.l_dim * self.c_dim)\n",
    "        return s\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "\n",
    "        # encode x to get the mu and variance parameters\n",
    "        x_encoded = self.encoder(x)\n",
    "        \n",
    "        q = self.fc_z(x_encoded)\n",
    "        q = q.view(-1, self.l_dim, self.c_dim)\n",
    "        z = self.reparameterize(q)\n",
    "\n",
    "        # decoded\n",
    "        x_hat = self.decoder(z)\n",
    "\n",
    "        y_pred = self.head(x_hat)\n",
    "\n",
    "        if batch_idx % self.interval == 0:\n",
    "            self.t = torch.nn.Parameter(torch.max(self.t * torch.exp(- self.rate * batch_idx),\n",
    "                                   self.min_t))\n",
    "\n",
    "        # reconstruction loss\n",
    "        recons_loss = self.gaussian_likelihood(x_hat, self.log_scale, x) \n",
    "\n",
    "        # kl\n",
    "        kl = self.kl_divergence(q)\n",
    "\n",
    "        label_error = nn.functional.cross_entropy(y_pred, y)\n",
    "\n",
    "        # elbo\n",
    "        elbo = (self.kl_coeff)*kl - self.alpha * recons_loss\n",
    "        elbo = elbo.mean()\n",
    "\n",
    "        self.log_dict({\n",
    "            'elbo': elbo,\n",
    "            'kl': -kl.mean(),\n",
    "            'recon_loss': recons_loss.mean(),\n",
    "            'cce' : label_error\n",
    "        })\n",
    "\n",
    "        return elbo + label_error\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        x_encoded = self.encoder(x)\n",
    "        q = self.fc_z(x_encoded)\n",
    "        x_hat = self.decoder(q)\n",
    "        y_hat = self.head(x_hat)\n",
    "        \n",
    "        loss = nn.functional.cross_entropy(y_hat, y)\n",
    "        self.log(\"val_loss\", loss)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_15319/938304261.py:74: UnderReviewWarning: The feature resnet18_encoder is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
      "  self.encoder = resnet18_encoder(False, False)\n",
      "/home/andrew/anaconda3/envs/torch/lib/python3.10/site-packages/pl_bolts/models/autoencoders/components.py:334: UnderReviewWarning: The feature ResNetEncoder is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
      "  return ResNetEncoder(EncoderBlock, [2, 2, 2, 2], first_conv, maxpool1)\n",
      "/home/andrew/anaconda3/envs/torch/lib/python3.10/site-packages/pl_bolts/models/autoencoders/components.py:236: UnderReviewWarning: The feature EncoderBlock is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
      "  layers.append(block(self.inplanes, planes, stride, downsample))\n",
      "/home/andrew/anaconda3/envs/torch/lib/python3.10/site-packages/pl_bolts/models/autoencoders/components.py:56: UnderReviewWarning: The feature conv3x3 is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
      "  self.conv1 = conv3x3(inplanes, planes, stride)\n",
      "/home/andrew/anaconda3/envs/torch/lib/python3.10/site-packages/pl_bolts/models/autoencoders/components.py:231: UnderReviewWarning: The feature conv1x1 is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
      "  conv1x1(self.inplanes, planes * block.expansion, stride),\n",
      "/tmp/ipykernel_15319/938304261.py:75: UnderReviewWarning: The feature resnet18_decoder is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
      "  self.decoder = resnet18_decoder(\n",
      "/home/andrew/anaconda3/envs/torch/lib/python3.10/site-packages/pl_bolts/models/autoencoders/components.py:339: UnderReviewWarning: The feature ResNetDecoder is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
      "  return ResNetDecoder(DecoderBlock, [2, 2, 2, 2], latent_dim, input_height, first_conv, maxpool1)\n",
      "/home/andrew/anaconda3/envs/torch/lib/python3.10/site-packages/pl_bolts/models/autoencoders/components.py:301: UnderReviewWarning: The feature resize_conv1x1 is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
      "  resize_conv1x1(self.inplanes, planes * block.expansion, scale),\n",
      "/home/andrew/anaconda3/envs/torch/lib/python3.10/site-packages/pl_bolts/models/autoencoders/components.py:45: UnderReviewWarning: The feature Interpolate is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
      "  return nn.Sequential(Interpolate(scale_factor=scale), conv1x1(in_planes, out_planes))\n",
      "/home/andrew/anaconda3/envs/torch/lib/python3.10/site-packages/pl_bolts/models/autoencoders/components.py:306: UnderReviewWarning: The feature DecoderBlock is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
      "  layers.append(block(self.inplanes, planes, scale, upsample))\n",
      "/home/andrew/anaconda3/envs/torch/lib/python3.10/site-packages/pl_bolts/models/autoencoders/components.py:132: UnderReviewWarning: The feature resize_conv3x3 is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
      "  self.conv1 = resize_conv3x3(inplanes, inplanes)\n"
     ]
    }
   ],
   "source": [
    "head = classifier_head([64, 64, 32, 16], [32, 16], 32, 1, 10)\n",
    "model = VAEclassifier(head, 512, 10, 10, 32, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VAEclassifier(\n",
       "  (encoder): ResNetEncoder(\n",
       "    (conv1): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): EncoderBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): EncoderBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): EncoderBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): EncoderBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): EncoderBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): EncoderBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): EncoderBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): EncoderBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  )\n",
       "  (decoder): ResNetDecoder(\n",
       "    (linear): Linear(in_features=100, out_features=8192, bias=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): DecoderBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Sequential(\n",
       "          (0): Interpolate()\n",
       "          (1): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (upsample): Sequential(\n",
       "          (0): Sequential(\n",
       "            (0): Interpolate()\n",
       "            (1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          )\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): DecoderBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): DecoderBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Sequential(\n",
       "          (0): Interpolate()\n",
       "          (1): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (upsample): Sequential(\n",
       "          (0): Sequential(\n",
       "            (0): Interpolate()\n",
       "            (1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          )\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): DecoderBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): DecoderBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Sequential(\n",
       "          (0): Interpolate()\n",
       "          (1): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (upsample): Sequential(\n",
       "          (0): Sequential(\n",
       "            (0): Interpolate()\n",
       "            (1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          )\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): DecoderBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): DecoderBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): DecoderBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (upscale): Interpolate()\n",
       "    (upscale1): Interpolate()\n",
       "    (conv1): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  )\n",
       "  (head): classifier_head(\n",
       "    (classifier): Sequential(\n",
       "      (0): Sequential(\n",
       "        (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (2): Sequential(\n",
       "        (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (3): Sequential(\n",
       "        (0): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (4): Flatten(start_dim=1, end_dim=-1)\n",
       "      (5): Sequential(\n",
       "        (0): Linear(in_features=9216, out_features=32, bias=True)\n",
       "        (1): ReLU()\n",
       "      )\n",
       "      (6): Sequential(\n",
       "        (0): Linear(in_features=32, out_features=16, bias=True)\n",
       "        (1): ReLU()\n",
       "      )\n",
       "      (7): Sequential(\n",
       "        (0): Linear(in_features=16, out_features=10, bias=True)\n",
       "        (1): Softmax(dim=None)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (fc_z): Linear(in_features=512, out_features=100, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8 | packaged by conda-forge | (main, Nov 22 2022, 08:26:04) [GCC 10.4.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c55daa462e78c237f22bb9bcab3632c9d16be55e0aa53cce53022e2d5bcdb6d9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

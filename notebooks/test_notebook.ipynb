{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch \n",
    "from typing import Any, NamedTuple\n",
    "\n",
    "from torch.nn import functional as F\n",
    "\n",
    "nn = torch.nn\n",
    "f = nn.functional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model_Config(NamedTuple):\n",
    "    num_heads : Any # How many decoder-classifer pairs\n",
    "    encoder : Any # Encoder function\n",
    "    decoder : Any # Decoder function\n",
    "    head : Any # Classifier function\n",
    "    input_layer : Any # Task specific input spec\n",
    "    n_class : Any # Number of Classes\n",
    "    out_dim : Any # Size of Image\n",
    "    hard : Any # argmax (T) or softmax (F)\n",
    "\n",
    "class Encoder_Config(NamedTuple):\n",
    "    in_dim : Any\n",
    "    n_class : Any \n",
    "    n_dist : Any # Number of categorical distributions\n",
    "    stack : Any # Internal Structure\n",
    "    tau : Any # Temperature variable\n",
    "\n",
    "class Decoder_Config(NamedTuple):\n",
    "    n_class : Any \n",
    "    n_dist : Any \n",
    "    stack : Any \n",
    "    latent_square : Any # Size of reshaped sampled logits\n",
    "    out_dim : Any\n",
    "    tau : Any \n",
    "\n",
    "class Head_Config(NamedTuple):\n",
    "    n_class : Any\n",
    "    base : Any # Task-specific layers\n",
    "    stack : Any \n",
    "    dense_activation : Any\n",
    "    in_dim : Any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_encoder(config):\n",
    "    def encoder():\n",
    "        layers = [] \n",
    "        in_dim = config.in_dim\n",
    "\n",
    "        for size in config.stack[:-1]:\n",
    "            layers.append(\n",
    "                nn.Sequential(\n",
    "                    nn.Conv2d(in_dim, out_channels=size,\n",
    "                                kernel_size=config.kernel, stride=config.stride, padding=config.padding),\n",
    "                        nn.BatchNorm2d(size),\n",
    "                        nn.LeakyReLU()\n",
    "                )\n",
    "            )\n",
    "            in_dim = size\n",
    "            \n",
    "        layers.append(\n",
    "            nn.Sequential(\n",
    "                nn.Conv2d(in_dim, out_channels=config.stack[-1],\n",
    "                                kernel_size=config.kernel, stride=config.stride, padding=config.padding)\n",
    "            )\n",
    "        )\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "    return encoder\n",
    "\n",
    "def init_decoder(config):\n",
    "    def decoder():\n",
    "        layers = [] \n",
    "\n",
    "        for i in range(len(config.stack) - 1):\n",
    "            layers.append(\n",
    "                nn.Sequential(\n",
    "                    nn.ConvTranspose2d(config.stack[i], out_channels=config.stack[i+1],\n",
    "                                kernel_size=config.kernel, stride=config.stride, padding=config.padding, output_padding=1),\n",
    "                        nn.BatchNorm2d(config.stack[i+1]),\n",
    "                        nn.LeakyReLU()\n",
    "                )\n",
    "            )\n",
    "\n",
    "        layers.append(\n",
    "            nn.Sequential(\n",
    "                nn.ConvTranspose2d(config.stack[-2], out_channels=config.stack[-1],\n",
    "                                kernel_size=config.kernel, stride=config.stride, padding=config.padding, output_padding=1)\n",
    "            )\n",
    "        )\n",
    "\n",
    "        layers.append(\n",
    "            nn.Sequential(\n",
    "                nn.ConvTranspose2d(config.stack[-1],\n",
    "                                   config.stack[-1],\n",
    "                                   kernel_size=config.kernel,\n",
    "                                   stride=config.stride,\n",
    "                                   padding=config.padding,\n",
    "                                   output_padding=1),\n",
    "                nn.BatchNorm2d(config.stack[-1]),\n",
    "                nn.LeakyReLU(),\n",
    "                nn.Conv2d(config.stack[-1], out_channels=3,\n",
    "                            kernel_size=config.kernel, padding=config.padding),\n",
    "                nn.Tanh())\n",
    "            )\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "    return decoder\n",
    "\n",
    "def init_head(config):  \n",
    "    def head():\n",
    "        layers = []\n",
    "        if config.base:\n",
    "            layers.append(nn.Sequential(\n",
    "                config.base, \n",
    "                torch.flatten()\n",
    "            ))\n",
    "        else: layers.append(nn.Sequential(torch.flatten()))\n",
    "        for i in range(len(config.stack) - 1):\n",
    "            layers.append(nn.Sequential(\n",
    "                nn.LazyLinear(config.stack[i]),\n",
    "                nn.ReLU()\n",
    "            ))\n",
    "        layers.append(nn.Sequential(\n",
    "            nn.LazyLinear(config.stack[-1]),\n",
    "            nn.softmax()\n",
    "        ))\n",
    "        return nn.Sequential(*layers)\n",
    "    return head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CategoricalVAE(nn.Module):\n",
    "\n",
    "    def __init__(self,\n",
    "                 in_channels: int,\n",
    "                 latent_dim: int,\n",
    "                 head_func,\n",
    "                 categorical_dim: int = 40, # Num classes\n",
    "                 hidden_dims = None,\n",
    "                 temperature: float = 0.5,\n",
    "                 anneal_rate: float = 3e-5,\n",
    "                 anneal_interval: int = 100, # every 100 batches\n",
    "                 alpha: float = 30.,\n",
    "                 **kwargs) -> None:\n",
    "        super(CategoricalVAE, self).__init__()\n",
    "\n",
    "        self.latent_dim = latent_dim\n",
    "        self.categorical_dim = categorical_dim\n",
    "        self.temp = temperature\n",
    "        self.min_temp = temperature\n",
    "        self.anneal_rate = anneal_rate\n",
    "        self.anneal_interval = anneal_interval\n",
    "        self.alpha = alpha\n",
    "\n",
    "        modules = []\n",
    "        if hidden_dims is None:\n",
    "            hidden_dims = [32, 64, 128, 256, 512]\n",
    "\n",
    "        # Build Encoder\n",
    "        for h_dim in hidden_dims:\n",
    "            modules.append(\n",
    "                nn.Sequential(\n",
    "                    nn.Conv2d(in_channels, out_channels=h_dim,\n",
    "                              kernel_size= 3, stride= 2, padding  = 1),\n",
    "                    nn.BatchNorm2d(h_dim),\n",
    "                    nn.LeakyReLU())\n",
    "            )\n",
    "            in_channels = h_dim\n",
    "\n",
    "        self.encoder = nn.Sequential(*modules)\n",
    "        self.fc_z = nn.Linear(hidden_dims[-1]*4,\n",
    "                               self.latent_dim * self.categorical_dim)\n",
    "\n",
    "        # Build Decoder\n",
    "        modules = []\n",
    "\n",
    "        self.decoder_input = nn.Linear(self.latent_dim * self.categorical_dim\n",
    "                                       , hidden_dims[-1] * 4)\n",
    "\n",
    "        hidden_dims.reverse()\n",
    "\n",
    "        for i in range(len(hidden_dims) - 1):\n",
    "            modules.append(\n",
    "                nn.Sequential(\n",
    "                    nn.ConvTranspose2d(hidden_dims[i],\n",
    "                                       hidden_dims[i + 1],\n",
    "                                       kernel_size=3,\n",
    "                                       stride = 2,\n",
    "                                       padding=1,\n",
    "                                       output_padding=1),\n",
    "                    nn.BatchNorm2d(hidden_dims[i + 1]),\n",
    "                    nn.LeakyReLU())\n",
    "            )\n",
    "\n",
    "\n",
    "\n",
    "        self.decoder = nn.Sequential(*modules)\n",
    "\n",
    "        self.final_layer = nn.Sequential(\n",
    "                            nn.ConvTranspose2d(hidden_dims[-1],\n",
    "                                               hidden_dims[-1],\n",
    "                                               kernel_size=3,\n",
    "                                               stride=2,\n",
    "                                               padding=1,\n",
    "                                               output_padding=1),\n",
    "                            nn.BatchNorm2d(hidden_dims[-1]),\n",
    "                            nn.LeakyReLU(),\n",
    "                            nn.Conv2d(hidden_dims[-1], out_channels= 3,\n",
    "                                      kernel_size= 3, padding= 1),\n",
    "                            nn.Tanh())\n",
    "\n",
    "        self.head = init_head()\n",
    "        self.sampling_dist = torch.distributions.OneHotCategorical(1. / categorical_dim * torch.ones((self.categorical_dim, 1)))\n",
    "\n",
    "    def encode(self, input):\n",
    "        \"\"\"\n",
    "        Encodes the input by passing through the encoder network\n",
    "        and returns the latent codes.\n",
    "        :param input: (Tensor) Input tensor to encoder [B x C x H x W]\n",
    "        :return: (Tensor) Latent code [B x D x Q]\n",
    "        \"\"\"\n",
    "        result = self.encoder(input)\n",
    "        result = torch.flatten(result, start_dim=1)\n",
    "\n",
    "        # Split the result into mu and var components\n",
    "        # of the latent Gaussian distribution\n",
    "        z = self.fc_z(result)\n",
    "        z = z.view(-1, self.latent_dim, self.categorical_dim)\n",
    "        return [z]\n",
    "\n",
    "    def decode(self, z):\n",
    "        \"\"\"\n",
    "        Maps the given latent codes\n",
    "        onto the image space.\n",
    "        :param z: (Tensor) [B x D x Q]\n",
    "        :return: (Tensor) [B x C x H x W]\n",
    "        \"\"\"\n",
    "        result = self.decoder_input(z)\n",
    "        result = result.view(-1, 512, 2, 2)\n",
    "        result = self.decoder(result)\n",
    "        result = self.final_layer(result)\n",
    "        return result\n",
    "\n",
    "    def reparameterize(self, z, eps:float = 1e-7):\n",
    "        \"\"\"\n",
    "        Gumbel-softmax trick to sample from Categorical Distribution\n",
    "        :param z: (Tensor) Latent Codes [B x D x Q]\n",
    "        :return: (Tensor) [B x D]\n",
    "        \"\"\"\n",
    "        # Sample from Gumbel\n",
    "        u = torch.rand_like(z)\n",
    "        g = - torch.log(- torch.log(u + eps) + eps)\n",
    "\n",
    "        # Gumbel-Softmax sample\n",
    "        s = F.softmax((z + g) / self.temp, dim=-1)\n",
    "        s = s.view(-1, self.latent_dim * self.categorical_dim)\n",
    "        return s\n",
    "\n",
    "\n",
    "    def forward(self, input, **kwargs):\n",
    "        q = self.encode(input)[0]\n",
    "        z = self.reparameterize(q)\n",
    "        x = self.decode(z)\n",
    "        y_pred = self.head(x)\n",
    "        return  [x, input, q, y_pred]\n",
    "\n",
    "    def loss_function(self,\n",
    "                      *args,\n",
    "                      **kwargs) -> dict:\n",
    "        \"\"\"\n",
    "        Computes the VAE loss function.\n",
    "        KL(N(\\mu, \\sigma), N(0, 1)) = \\log \\frac{1}{\\sigma} + \\frac{\\sigma^2 + \\mu^2}{2} - \\frac{1}{2}\n",
    "        :param args:\n",
    "        :param kwargs:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        recons = args[0]\n",
    "        input = args[1]\n",
    "        q = args[2]\n",
    "        y_pred = args[4]\n",
    "        y = args[3]\n",
    "\n",
    "        q_p = F.softmax(q, dim=-1) # Convert the categorical codes into probabilities\n",
    "\n",
    "        kld_weight = kwargs['M_N'] # Account for the minibatch samples from the dataset\n",
    "        batch_idx = kwargs['batch_idx']\n",
    "\n",
    "        # Anneal the temperature at regular intervals\n",
    "        if batch_idx % self.anneal_interval == 0 and self.training:\n",
    "            self.temp = np.maximum(self.temp * np.exp(- self.anneal_rate * batch_idx),\n",
    "                                   self.min_temp)\n",
    "\n",
    "        recons_loss =F.mse_loss(recons, input, reduction='mean')\n",
    "        cce_loss = f.cross_entropy(y, y_pred, reduction='mean')\n",
    "\n",
    "        # KL divergence between gumbel-softmax distribution\n",
    "        eps = 1e-7\n",
    "\n",
    "        # Entropy of the logits\n",
    "        h1 = q_p * torch.log(q_p + eps)\n",
    "\n",
    "        # Cross entropy with the categorical distribution\n",
    "        h2 = q_p * np.log(1. / self.categorical_dim + eps)\n",
    "        kld_loss = torch.mean(torch.sum(h1 - h2, dim =(1,2)), dim=0)\n",
    "\n",
    "        # kld_weight = 1.2\n",
    "        loss = self.alpha * recons_loss + kld_weight * kld_loss + cce_loss\n",
    "        return {'loss': loss, 'Reconstruction_Loss':recons_loss, 'KLD': -kld_loss, 'CCE': cce_loss}\n",
    "\n",
    "    def sample(self,\n",
    "               num_samples:int,\n",
    "               current_device: int, **kwargs):\n",
    "        \"\"\"\n",
    "        Samples from the latent space and return the corresponding\n",
    "        image space map.\n",
    "        :param num_samples: (Int) Number of samples\n",
    "        :param current_device: (Int) Device to run the model\n",
    "        :return: (Tensor)\n",
    "        \"\"\"\n",
    "        # [S x D x Q]\n",
    "\n",
    "        M = num_samples * self.latent_dim\n",
    "        np_y = np.zeros((M, self.categorical_dim), dtype=np.float32)\n",
    "        np_y[range(M), np.random.choice(self.categorical_dim, M)] = 1\n",
    "        np_y = np.reshape(np_y, [M // self.latent_dim, self.latent_dim, self.categorical_dim])\n",
    "        z = torch.from_numpy(np_y)\n",
    "\n",
    "        # z = self.sampling_dist.sample((num_samples * self.latent_dim, ))\n",
    "        z = z.view(num_samples, self.latent_dim * self.categorical_dim).to(current_device)\n",
    "        samples = self.decode(z)\n",
    "        return samples\n",
    "\n",
    "    def generate(self, x, **kwargs):\n",
    "        \"\"\"\n",
    "        Given an input image x, returns the reconstructed image\n",
    "        :param x: (Tensor) [B x C x H x W]\n",
    "        :return: (Tensor) [B x C x H x W]\n",
    "        \"\"\"\n",
    "\n",
    "        return self.forward(x)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_CLASS = 10\n",
    "N_DIST = 20\n",
    "STACK = []\n",
    "LATENT_SQUARE = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head_config = Head_Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head_fn = init_encoder(head_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class model_config:\n",
    "    x = 1\n",
    "    y = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CategoricalVAE(model_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = None \n",
    "loss = None \n",
    "EPOCHS = 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    for i, data in train:\n",
    "        x, y = data\n",
    "        pred = model.forward(x) + y\n",
    "        loss_val = model.loss(*pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.6 (main, Nov 14 2022, 16:10:14) [GCC 11.3.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
